{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed405a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import vgg19\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "import gdown\n",
    "from collections import defaultdict\n",
    "\n",
    "# Metrics\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import lpips\n",
    "import pandas as pd\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"üöÄ Using device: {device}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74be41a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. DOWNLOAD LOL-V2 DATASET\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì• DOWNLOADING LOL-V2 DATASET\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "data_dir = Path('./data')\n",
    "data_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Google Drive link (contains both Real and Synthetic)\n",
    "file_id = '1dzuLCk9_gE2bFF222n3-7GVUlSVHpMYC'\n",
    "zip_path = data_dir / 'LOL-v2.zip'\n",
    "extract_path = data_dir / 'LOL-v2'\n",
    "\n",
    "if not extract_path.exists():\n",
    "    print(\"üì• Downloading from Google Drive...\")\n",
    "    url = f'https://drive.google.com/uc?id={file_id}'\n",
    "    gdown.download(url, str(zip_path), quiet=False, fuzzy=True)\n",
    "\n",
    "    print(\"üì¶ Extracting dataset...\")\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(data_dir)\n",
    "\n",
    "    zip_path.unlink()\n",
    "    print(\"‚úÖ Dataset ready!\")\n",
    "else:\n",
    "    print(\"‚úÖ Dataset already exists!\")\n",
    "\n",
    "# Find Real and Synthetic folders\n",
    "real_path = None\n",
    "synthetic_path = None\n",
    "\n",
    "for path in extract_path.rglob('*'):\n",
    "    if path.is_dir():\n",
    "        if 'real' in path.name.lower() and 'captured' in path.name.lower():\n",
    "            real_path = path\n",
    "        elif path.name.lower() == 'synthetic':\n",
    "            synthetic_path = path\n",
    "\n",
    "print(f\"\\nüìÅ Dataset structure:\")\n",
    "print(f\"   Real: {real_path}\")\n",
    "print(f\"   Synthetic: {synthetic_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1fb1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. DATASET CLASS & DATA LOADING\n",
    "# ============================================================================\n",
    "\n",
    "\n",
    "def extract_id(filename):\n",
    "    m = re.search(r'(\\d+)', filename)\n",
    "    return m.group(1) if m else None\n",
    "\n",
    "\n",
    "class LOLv2Dataset(Dataset):\n",
    " \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_paths,\n",
    "        split='train',\n",
    "        img_size=256,\n",
    "        verbose=True\n",
    "    ):\n",
    "        self.img_size = img_size\n",
    "        self.split = split.lower()\n",
    "        self.pairs = []\n",
    "\n",
    "        assert self.split in ['train', 'test']\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nüìä LOADING {self.split.upper()} DATASET\")\n",
    "\n",
    "        for data_path in data_paths:\n",
    "            data_path = Path(data_path)\n",
    "            dataset_name = data_path.name\n",
    "\n",
    "            split_dir = data_path / ('Train' if self.split == 'train' else 'Test')\n",
    "            low_dir = split_dir / 'Low'\n",
    "            normal_dir = split_dir / 'Normal'\n",
    "\n",
    "            if not low_dir.exists() or not normal_dir.exists():\n",
    "                if verbose:\n",
    "                    print(f\"‚ö†Ô∏è  Skip {dataset_name} ({self.split}) ‚Äì missing Low/Normal\")\n",
    "                continue\n",
    "\n",
    "            # Collect files\n",
    "            low_imgs = list(low_dir.glob('*.png')) + list(low_dir.glob('*.jpg'))\n",
    "            normal_imgs = list(normal_dir.glob('*.png')) + list(normal_dir.glob('*.jpg'))\n",
    "\n",
    "            # Build Normal dict by ID\n",
    "            normal_dict = {}\n",
    "            for p in normal_imgs:\n",
    "                key = extract_id(p.name)\n",
    "                if key is not None:\n",
    "                    normal_dict[key] = p\n",
    "\n",
    "            count_before = len(self.pairs)\n",
    "\n",
    "            for low_img in low_imgs:\n",
    "                key = extract_id(low_img.name)\n",
    "                if key is None:\n",
    "                    continue\n",
    "\n",
    "                if key in normal_dict:\n",
    "                    self.pairs.append((\n",
    "                        str(low_img),\n",
    "                        str(normal_dict[key])\n",
    "                    ))\n",
    "\n",
    "            count_after = len(self.pairs)\n",
    "\n",
    "            if verbose:\n",
    "                print(\n",
    "                    f\"   - {dataset_name:<15}: \"\n",
    "                    f\"{count_after - count_before} pairs\"\n",
    "                )\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"‚úÖ TOTAL {self.split.upper()} PAIRS: {len(self.pairs)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        low_path, normal_path = self.pairs[idx]\n",
    "\n",
    "        # Load images\n",
    "        low_img = cv2.imread(low_path)\n",
    "        normal_img = cv2.imread(normal_path)\n",
    "\n",
    "        if low_img is None or normal_img is None:\n",
    "            raise RuntimeError(f\"Failed to load image pair:\\n{low_path}\\n{normal_path}\")\n",
    "\n",
    "        # BGR -> RGB\n",
    "        low_img = cv2.cvtColor(low_img, cv2.COLOR_BGR2RGB)\n",
    "        normal_img = cv2.cvtColor(normal_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Resize\n",
    "        low_img = cv2.resize(low_img, (self.img_size, self.img_size))\n",
    "        normal_img = cv2.resize(normal_img, (self.img_size, self.img_size))\n",
    "\n",
    "        # Normalize\n",
    "        low_img = low_img.astype(np.float32) / 255.0\n",
    "        normal_img = normal_img.astype(np.float32) / 255.0\n",
    "\n",
    "        # HWC -> CHW\n",
    "        low_img = torch.from_numpy(low_img).permute(2, 0, 1)\n",
    "        normal_img = torch.from_numpy(normal_img).permute(2, 0, 1)\n",
    "\n",
    "        return low_img, normal_img\n",
    "\n",
    "# Create combined dataset (Real + Synthetic)\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä LOADING DATASET: Real + Synthetic Combined\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "train_dataset = LOLv2Dataset(\n",
    "    data_paths=[real_path, synthetic_path],\n",
    "    split='train',\n",
    "    img_size=256\n",
    ")\n",
    "\n",
    "test_dataset = LOLv2Dataset(\n",
    "    data_paths=[real_path, synthetic_path],\n",
    "    split='test',\n",
    "    img_size=256\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Total pairs: {len(train_dataset) + len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3001792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. ZERO-DCE MODEL ARCHITECTURE\n",
    "# ============================================================================\n",
    "\n",
    "class DCENet(nn.Module):\n",
    "    \"\"\"Zero-DCE Network\"\"\"\n",
    "\n",
    "    def __init__(self, num_iterations=8):\n",
    "        super(DCENet, self).__init__()\n",
    "        self.num_iterations = num_iterations\n",
    "\n",
    "        # Encoder\n",
    "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "\n",
    "        # Decoder\n",
    "        self.conv5 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(32, 3 * num_iterations, 3, padding=1)\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        x1 = self.relu(self.conv1(x))\n",
    "        x2 = self.relu(self.conv2(x1))\n",
    "        x3 = self.relu(self.conv3(x2))\n",
    "        x4 = self.relu(self.conv4(x3))\n",
    "\n",
    "        # Decoder\n",
    "        x5 = self.relu(self.conv5(x4))\n",
    "        x6 = self.relu(self.conv6(x5))\n",
    "        A = self.tanh(self.conv7(x6))\n",
    "\n",
    "        # Apply curve iteratively\n",
    "        enhanced = x\n",
    "        for i in range(self.num_iterations):\n",
    "            curve_params = A[:, i*3:(i+1)*3, :, :]\n",
    "            enhanced = enhanced + curve_params * enhanced * (1 - enhanced)\n",
    "\n",
    "        return enhanced, A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d754f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. LOSS FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "class CharbonnierLoss(nn.Module):\n",
    "    def __init__(self, epsilon=1e-3):\n",
    "        super(CharbonnierLoss, self).__init__()\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        diff = pred - target\n",
    "        loss = torch.mean(torch.sqrt(diff * diff + self.epsilon * self.epsilon))\n",
    "        return loss\n",
    "\n",
    "class PerceptualLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PerceptualLoss, self).__init__()\n",
    "        vgg = vgg19(pretrained=True).features\n",
    "        \n",
    "        self.layers = nn.ModuleList([\n",
    "            vgg[:4], vgg[:9], vgg[:18], vgg[:27]\n",
    "        ])\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.layers = self.layers.to(device)\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        loss = 0\n",
    "        for layer in self.layers:\n",
    "            pred_feat = layer(pred)\n",
    "            target_feat = layer(target)\n",
    "            loss += F.mse_loss(pred_feat, target_feat)\n",
    "        return loss\n",
    "\n",
    "class ColorConstancyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ColorConstancyLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, enhanced):\n",
    "        mean_rgb = torch.mean(enhanced, dim=(2, 3), keepdim=True)\n",
    "        mr, mg, mb = mean_rgb[:, 0:1], mean_rgb[:, 1:2], mean_rgb[:, 2:3]\n",
    "        \n",
    "        d_rg = torch.pow(mr - mg, 2)\n",
    "        d_rb = torch.pow(mr - mb, 2)\n",
    "        d_gb = torch.pow(mg - mb, 2)\n",
    "        \n",
    "        loss = torch.sqrt(torch.pow(d_rg, 2) + torch.pow(d_rb, 2) + torch.pow(d_gb, 2))\n",
    "        return torch.mean(loss)\n",
    "\n",
    "class ExposureControlLoss(nn.Module):\n",
    "    def __init__(self, patch_size=16, mean_val=0.6):\n",
    "        super(ExposureControlLoss, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.mean_val = mean_val\n",
    "        self.pool = nn.AvgPool2d(patch_size)\n",
    "    \n",
    "    def forward(self, enhanced):\n",
    "        enhanced_gray = 0.299 * enhanced[:, 0] + 0.587 * enhanced[:, 1] + 0.114 * enhanced[:, 2]\n",
    "        enhanced_gray = enhanced_gray.unsqueeze(1)\n",
    "        mean = self.pool(enhanced_gray)\n",
    "        return torch.mean(torch.pow(mean - self.mean_val, 2))\n",
    "\n",
    "class CombinedLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CombinedLoss, self).__init__()\n",
    "        self.charbonnier = CharbonnierLoss()\n",
    "        self.perceptual = PerceptualLoss()\n",
    "        self.color = ColorConstancyLoss()\n",
    "        self.exposure = ExposureControlLoss()\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        losses = {}\n",
    "        \n",
    "        losses['charbonnier'] = self.charbonnier(pred, target)\n",
    "        losses['perceptual'] = self.perceptual(pred, target)\n",
    "        losses['color'] = self.color(pred)\n",
    "        losses['exposure'] = self.exposure(pred)\n",
    "        \n",
    "        total_loss = losses['charbonnier'] + \\\n",
    "                     0.05 * losses['perceptual'] + \\\n",
    "                     0.5 * losses['color'] + \\\n",
    "                     0.1 * losses['exposure']\n",
    "        \n",
    "        losses['total'] = total_loss\n",
    "        return total_loss, losses\n",
    "\n",
    "\n",
    "# Loss configurations\n",
    "LOSS_CONFIGS = {\n",
    "    'l1': 'l1',\n",
    "    'charbonnier': 'charbonnier',\n",
    "    'charbonnier_perceptual': 'charbonnier_perceptual',\n",
    "    'charbonnier_perceptual_ssim': 'charbonnier_perceptual_ssim',\n",
    "    'charbonnier_perceptual_color_exposure': 'charbonnier_perceptual_color_exposure'\n",
    "}\n",
    "\n",
    "print(f\"\\nüéØ Loss Configurations:\")\n",
    "for i, name in enumerate(LOSS_CONFIGS.keys(), 1):\n",
    "    print(f\"   {i}. {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672ff9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. METRICS CALCULATION\n",
    "# ============================================================================\n",
    "\n",
    "class MetricsCalculator:\n",
    "    \"\"\"Calculate PSNR, SSIM, and LPIPS metrics\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.lpips_model = lpips.LPIPS(net='alex').to(device)\n",
    "        self.lpips_model.eval()\n",
    "\n",
    "    def calculate_psnr(self, pred, target):\n",
    "        pred_np = pred.cpu().numpy().transpose(1, 2, 0)\n",
    "        target_np = target.cpu().numpy().transpose(1, 2, 0)\n",
    "        return psnr(target_np, pred_np, data_range=1.0)\n",
    "\n",
    "    def calculate_ssim(self, pred, target):\n",
    "        pred_np = pred.cpu().numpy().transpose(1, 2, 0)\n",
    "        target_np = target.cpu().numpy().transpose(1, 2, 0)\n",
    "        return ssim(target_np, pred_np, data_range=1.0, channel_axis=2)\n",
    "\n",
    "    def calculate_lpips(self, pred, target):\n",
    "        with torch.no_grad():\n",
    "            pred_norm = pred * 2 - 1\n",
    "            target_norm = target * 2 - 1\n",
    "            return self.lpips_model(pred_norm, target_norm).item()\n",
    "\n",
    "    def calculate_all(self, pred, target):\n",
    "        return {\n",
    "            'psnr': self.calculate_psnr(pred, target),\n",
    "            'ssim': self.calculate_ssim(pred, target),\n",
    "            'lpips': self.calculate_lpips(pred.unsqueeze(0), target.unsqueeze(0))\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd577597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. TRAINING FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Training pipeline\"\"\"\n",
    "\n",
    "    def __init__(self, model, train_loader, test_loader, loss_fn,\n",
    "                 optimizer, device, save_dir, experiment_name):\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.test_loader = test_loader\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "        self.save_dir = Path(save_dir)\n",
    "        self.experiment_name = experiment_name\n",
    "        self.metrics_calc = MetricsCalculator()\n",
    "\n",
    "        self.save_dir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "        self.history = defaultdict(list)\n",
    "        self.best_psnr = 0\n",
    "\n",
    "    def train_epoch(self):\n",
    "        self.model.train()\n",
    "        epoch_losses = defaultdict(float)\n",
    "\n",
    "        pbar = tqdm(self.train_loader, desc='Training')\n",
    "        for batch_idx, (low, normal) in enumerate(pbar):\n",
    "            try:\n",
    "                low, normal = low.to(self.device), normal.to(self.device)\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                enhanced, _ = self.model(low)\n",
    "                loss, loss_dict = self.loss_fn(enhanced, normal)\n",
    "\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                for k, v in loss_dict.items():\n",
    "                    epoch_losses[k] += v.item()\n",
    "\n",
    "                pbar.set_postfix({'loss': f\"{loss.item():.4f}\"})\n",
    "\n",
    "            except RuntimeError as e:\n",
    "                if 'out of memory' in str(e):\n",
    "                    print(f\"\\n‚ö†Ô∏è  OOM at batch {batch_idx}. Clearing cache...\")\n",
    "                    torch.cuda.empty_cache()\n",
    "                    continue\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "        for k in epoch_losses:\n",
    "            epoch_losses[k] /= len(self.train_loader)\n",
    "\n",
    "        return dict(epoch_losses)\n",
    "\n",
    "    def evaluate(self):\n",
    "        self.model.eval()\n",
    "        metrics = defaultdict(list)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for low, normal in tqdm(self.test_loader, desc='Evaluating'):\n",
    "                low, normal = low.to(self.device), normal.to(self.device)\n",
    "\n",
    "                enhanced, _ = self.model(low)\n",
    "\n",
    "                for i in range(enhanced.shape[0]):\n",
    "                    m = self.metrics_calc.calculate_all(enhanced[i], normal[i])\n",
    "                    for k, v in m.items():\n",
    "                        metrics[k].append(v)\n",
    "\n",
    "        avg_metrics = {k: np.mean(v) for k, v in metrics.items()}\n",
    "        return avg_metrics\n",
    "\n",
    "    def save_checkpoint(self, epoch, metrics, is_best=False):\n",
    "        checkpoint = {\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': self.model.state_dict(),\n",
    "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
    "            'metrics': metrics,\n",
    "            'history': dict(self.history)\n",
    "        }\n",
    "\n",
    "        if (epoch + 1) % 20 == 0:\n",
    "            path = self.save_dir / f'{self.experiment_name}_epoch_{epoch+1}.pth'\n",
    "            torch.save(checkpoint, path)\n",
    "            print(f\"üíæ Saved checkpoint: {path}\")\n",
    "\n",
    "        if is_best:\n",
    "            path = self.save_dir / f'{self.experiment_name}_best.pth'\n",
    "            torch.save(checkpoint, path)\n",
    "            print(f\"üèÜ Saved best model: {path}\")\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        print(f\"\\nüöÄ Starting training: {self.experiment_name}\")\n",
    "        print(f\"   Epochs: {num_epochs}\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"\\nüìÖ Epoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "            train_losses = self.train_epoch()\n",
    "            test_metrics = self.evaluate()\n",
    "\n",
    "            print(f\"\\nüìä Results:\")\n",
    "            print(f\"   Train Loss: {train_losses['total']:.4f}\")\n",
    "            print(f\"   Test PSNR: {test_metrics['psnr']:.2f} dB\")\n",
    "            print(f\"   Test SSIM: {test_metrics['ssim']:.4f}\")\n",
    "            print(f\"   Test LPIPS: {test_metrics['lpips']:.4f}\")\n",
    "\n",
    "            self.history['train_loss'].append(train_losses['total'])\n",
    "            for k, v in test_metrics.items():\n",
    "                self.history[f'test_{k}'].append(v)\n",
    "\n",
    "            is_best = test_metrics['psnr'] > self.best_psnr\n",
    "            if is_best:\n",
    "                self.best_psnr = test_metrics['psnr']\n",
    "\n",
    "            self.save_checkpoint(epoch, test_metrics, is_best)\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        print(f\"\\n‚úÖ Training completed! Best PSNR: {self.best_psnr:.2f} dB\")\n",
    "        return self.history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9e19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. EXPERIMENT RUNNER\n",
    "# ============================================================================\n",
    "\n",
    "def run_experiment(train_dataset, test_dataset, loss_config,\n",
    "                   batch_size=16, num_epochs=100, lr=1e-4):\n",
    "    \"\"\"Run single experiment\"\"\"\n",
    "\n",
    "    experiment_name = f\"real_synthetic_{loss_config}\"\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"üî¨ EXPERIMENT: {experiment_name}\")\n",
    "    print(f\"{'='*70}\")\n",
    "\n",
    "    # Create data loaders\n",
    "    try:\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                 shuffle=True, num_workers=2, pin_memory=True)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                shuffle=False, num_workers=2, pin_memory=True)\n",
    "    except RuntimeError as e:\n",
    "        if 'out of memory' in str(e):\n",
    "            print(f\"‚ö†Ô∏è  OOM with batch_size={batch_size}, reducing to {batch_size//2}\")\n",
    "            batch_size = batch_size // 2\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                    shuffle=True, num_workers=2, pin_memory=True)\n",
    "            test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                   shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    model = DCENet(num_iterations=8).to(device)\n",
    "    loss_fn = CombinedLoss(loss_type=LOSS_CONFIGS[loss_config])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999))\n",
    "\n",
    "    save_dir = './checkpoints'\n",
    "    trainer = Trainer(model, train_loader, test_loader, loss_fn,\n",
    "                     optimizer, device, save_dir, experiment_name)\n",
    "\n",
    "    history = trainer.train(num_epochs)\n",
    "    final_metrics = trainer.evaluate()\n",
    "\n",
    "    return history, final_metrics, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331f6956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. RUN ALL EXPERIMENTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"üéØ\"*35)\n",
    "print(\"STARTING EXPERIMENTS: Real + Synthetic Combined\")\n",
    "print(\"üéØ\"*35)\n",
    "\n",
    "all_histories = {}\n",
    "all_metrics = {}\n",
    "all_models = {}\n",
    "\n",
    "for loss_config in LOSS_CONFIGS.keys():\n",
    "    try:\n",
    "        history, metrics, model = run_experiment(\n",
    "            train_dataset=train_dataset,\n",
    "            test_dataset=test_dataset,\n",
    "            loss_config=loss_config,\n",
    "            batch_size=16,\n",
    "            num_epochs=100,\n",
    "            lr=1e-4\n",
    "        )\n",
    "\n",
    "        exp_name = f\"real_synthetic_{loss_config}\"\n",
    "        all_histories[exp_name] = history\n",
    "        all_metrics[exp_name] = metrics\n",
    "        all_models[loss_config] = model\n",
    "\n",
    "        # Save results\n",
    "        Path('./results').mkdir(exist_ok=True)\n",
    "        results_file = f'./results/{exp_name}_results.json'\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump({\n",
    "                'history': {k: [float(v) for v in vals] for k, vals in history.items()},\n",
    "                'final_metrics': {k: float(v) for k, v in metrics.items()}\n",
    "            }, f, indent=2)\n",
    "\n",
    "        print(f\"‚úÖ {exp_name} completed!\")\n",
    "\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error in {loss_config}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211462b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. VISUALIZATION - BEST MODELS COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üì∏ CREATING BEST MODELS COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Select 3 fixed test samples for comparison\n",
    "sample_indices = [0, len(test_dataset)//2, len(test_dataset)-1]\n",
    "\n",
    "# Create figure: 3 rows (samples) x 7 columns (Low + 5 models + Normal)\n",
    "fig, axes = plt.subplots(3, 7, figsize=(21, 9))\n",
    "\n",
    "# Column headers\n",
    "col_headers = ['Low Input', 'L1 Loss', 'Charbonnier',\n",
    "               'Char+Percep', 'Char+Percep+SSIM',\n",
    "               'Char+Percep+Color+Exp', 'Ground Truth']\n",
    "\n",
    "for col, header in enumerate(col_headers):\n",
    "    axes[0, col].set_title(header, fontsize=10, fontweight='bold')\n",
    "\n",
    "# Load all models\n",
    "loaded_models = {}\n",
    "for loss_name in LOSS_CONFIGS.keys():\n",
    "    try:\n",
    "        checkpoint_path = f'./checkpoints/real_synthetic_{loss_name}_best.pth'\n",
    "        checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "        model = DCENet(num_iterations=8).to(device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        model.eval()\n",
    "\n",
    "        loaded_models[loss_name] = model\n",
    "        print(f\"‚úÖ Loaded {loss_name} model\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  Could not load {loss_name}: {e}\")\n",
    "\n",
    "# Generate comparisons for 3 samples\n",
    "with torch.no_grad():\n",
    "    for row, idx in enumerate(sample_indices):\n",
    "        low, normal = test_dataset[idx]\n",
    "\n",
    "        # Display low input\n",
    "        low_np = low.numpy().transpose(1, 2, 0)\n",
    "        axes[row, 0].imshow(np.clip(low_np, 0, 1))\n",
    "        axes[row, 0].axis('off')\n",
    "\n",
    "        # Display enhanced versions from each model\n",
    "        low_batch = low.unsqueeze(0).to(device)\n",
    "\n",
    "        for col, loss_name in enumerate(LOSS_CONFIGS.keys(), 1):\n",
    "            if loss_name in loaded_models:\n",
    "                enhanced, _ = loaded_models[loss_name](low_batch)\n",
    "                enhanced_np = enhanced.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "                axes[row, col].imshow(np.clip(enhanced_np, 0, 1))\n",
    "            else:\n",
    "                axes[row, col].text(0.5, 0.5, 'N/A', ha='center', va='center')\n",
    "            axes[row, col].axis('off')\n",
    "\n",
    "        # Display ground truth\n",
    "        normal_np = normal.numpy().transpose(1, 2, 0)\n",
    "        axes[row, 6].imshow(np.clip(normal_np, 0, 1))\n",
    "        axes[row, 6].axis('off')\n",
    "\n",
    "plt.suptitle('Best Models Comparison (Same 3 Test Samples)',\n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.savefig('./results/best_models_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"‚úÖ Saved comparison: ./results/best_models_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1941ad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. TRAINING CURVES & METRICS COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "# Plot training curves\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "metrics = ['train_loss', 'test_psnr', 'test_ssim', 'test_lpips']\n",
    "titles = ['Training Loss', 'Test PSNR (dB)', 'Test SSIM', 'Test LPIPS']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics, titles)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "\n",
    "    for exp_name, history in all_histories.items():\n",
    "        if metric in history:\n",
    "            label = exp_name.replace('real_synthetic_', '')\n",
    "            ax.plot(history[metric], label=label, linewidth=2)\n",
    "\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel(title)\n",
    "    ax.set_title(title)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./results/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"üìà Saved training curves: ./results/training_curves.png\")\n",
    "\n",
    "# Metrics comparison bar chart\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "loss_names = [k.replace('real_synthetic_', '') for k in all_metrics.keys()]\n",
    "psnr_vals = [all_metrics[k]['psnr'] for k in all_metrics.keys()]\n",
    "ssim_vals = [all_metrics[k]['ssim'] for k in all_metrics.keys()]\n",
    "lpips_vals = [all_metrics[k]['lpips'] for k in all_metrics.keys()]\n",
    "\n",
    "# PSNR\n",
    "axes[0].bar(range(len(loss_names)), psnr_vals, color='skyblue')\n",
    "axes[0].set_xticks(range(len(loss_names)))\n",
    "axes[0].set_xticklabels(loss_names, rotation=45, ha='right')\n",
    "axes[0].set_ylabel('PSNR (dB)')\n",
    "axes[0].set_title('PSNR Comparison')\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(psnr_vals):\n",
    "    axes[0].text(i, v, f'{v:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# SSIM\n",
    "axes[1].bar(range(len(loss_names)), ssim_vals, color='lightgreen')\n",
    "axes[1].set_xticks(range(len(loss_names)))\n",
    "axes[1].set_xticklabels(loss_names, rotation=45, ha='right')\n",
    "axes[1].set_ylabel('SSIM')\n",
    "axes[1].set_title('SSIM Comparison')\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(ssim_vals):\n",
    "    axes[1].text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# LPIPS\n",
    "axes[2].bar(range(len(loss_names)), lpips_vals, color='salmon')\n",
    "axes[2].set_xticks(range(len(loss_names)))\n",
    "axes[2].set_xticklabels(loss_names, rotation=45, ha='right')\n",
    "axes[2].set_ylabel('LPIPS')\n",
    "axes[2].set_title('LPIPS Comparison (lower is better)')\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "for i, v in enumerate(lpips_vals):\n",
    "    axes[2].text(i, v, f'{v:.4f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('./results/metrics_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"üìä Saved metrics comparison: ./results/metrics_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f373e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. FINAL SUMMARY\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üìä FINAL RESULTS SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "summary_data = []\n",
    "for exp_name, metrics in all_metrics.items():\n",
    "    summary_data.append({\n",
    "        'Loss Function': exp_name.replace('real_synthetic_', ''),\n",
    "        'PSNR (dB)': f\"{metrics['psnr']:.2f}\",\n",
    "        'SSIM': f\"{metrics['ssim']:.4f}\",\n",
    "        'LPIPS': f\"{metrics['lpips']:.4f}\"\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(\"\\n\" + df_summary.to_string(index=False))\n",
    "\n",
    "df_summary.to_csv('./results/final_summary.csv', index=False)\n",
    "print(\"\\nüíæ Saved summary: ./results/final_summary.csv\")\n",
    "\n",
    "# Best models\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üèÜ BEST PERFORMING MODELS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "best_psnr = max(all_metrics.items(), key=lambda x: x[1]['psnr'])\n",
    "best_ssim = max(all_metrics.items(), key=lambda x: x[1]['ssim'])\n",
    "best_lpips = min(all_metrics.items(), key=lambda x: x[1]['lpips'])\n",
    "\n",
    "print(f\"\\nü•á Best PSNR: {best_psnr[0].replace('real_synthetic_', '')}\")\n",
    "print(f\"   PSNR: {best_psnr[1]['psnr']:.2f} dB\")\n",
    "print(f\"   SSIM: {best_psnr[1]['ssim']:.4f}\")\n",
    "print(f\"   LPIPS: {best_psnr[1]['lpips']:.4f}\")\n",
    "\n",
    "print(f\"\\nü•á Best SSIM: {best_ssim[0].replace('real_synthetic_', '')}\")\n",
    "print(f\"   PSNR: {best_ssim[1]['psnr']:.2f} dB\")\n",
    "print(f\"   SSIM: {best_ssim[1]['ssim']:.4f}\")\n",
    "print(f\"   LPIPS: {best_ssim[1]['lpips']:.4f}\")\n",
    "\n",
    "print(f\"\\nü•á Best LPIPS: {best_lpips[0].replace('real_synthetic_', '')}\")\n",
    "print(f\"   PSNR: {best_lpips[1]['psnr']:.2f} dB\")\n",
    "print(f\"   SSIM: {best_lpips[1]['ssim']:.4f}\")\n",
    "print(f\"   LPIPS: {best_lpips[1]['lpips']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ ALL EXPERIMENTS COMPLETED!\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\"\"\n",
    "üìÅ Results saved in:\n",
    "   - Checkpoints: ./checkpoints/\n",
    "   - Visualizations: ./results/\n",
    "   - Best models comparison: ./results/best_models_comparison.png\n",
    "   - Training curves: ./results/training_curves.png\n",
    "   - Metrics comparison: ./results/metrics_comparison.png\n",
    "   - Summary: ./results/final_summary.csv\n",
    "\n",
    "üéâ Training pipeline completed successfully! üéâ\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
